Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Self-play/ELO,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.7807847,-1.9626436,4998.25,1200.25,-277.59999561309814,-277.59999561309814,1.0
20000,1.7782608,-1.9048147,4998.5,1200.5,-328.0999965071678,-328.0999965071678,1.0
30000,1.779583,-1.3987917,4998.5,1200.5,-266.1999972574413,-266.1999972574413,1.0
40000,1.778467,-1.7786026,4998.5,1200.9992804441454,-237.49999710172415,-237.49999710172415,1.0
50000,1.7704523,-1.8734887,4998.5,1200.9985608882907,-181.2499965876341,-181.2499965876341,1.0
60000,1.763659,-1.786882,4999.0,1200.9985608882907,-64.64999781176448,-64.64999781176448,1.0
70000,1.7520874,-1.5961765,4998.5,1200.9985608882907,-44.949997417628765,-44.949997417628765,1.0
80000,1.7562538,-1.4697071,4998.5,1200.9982021451403,-3.4499978572130203,-3.4499978572130203,1.0
90000,1.7207434,-1.4327127,4998.5,1201.4971279807764,31.60000206902623,31.60000206902623,1.0
100000,1.6970078,-1.4054329,4998.5,1201.4971279807764,30.550002094358206,30.550002094358206,1.0
110000,1.70229,-0.9532243,4999.0,1201.4949755247646,88.10000528395176,88.10000528395176,1.0
120000,1.6379324,-1.314746,4998.5,1201.4928292639047,88.1500051394105,88.1500051394105,1.0
130000,1.624523,-1.098122,4998.5,1201.4928292639047,75.85000359266996,75.85000359266996,1.0
140000,1.6153417,-1.003712,4998.5,1201.4928292639047,101.10000428184867,101.10000428184867,1.0
150000,1.5628425,-0.90139186,4998.5,1201.9928292639047,98.10000505298376,98.10000505298376,1.0
160000,1.5573854,-0.62418634,4998.75,1202.2424694852323,116.20000382140279,116.20000382140279,1.0
170000,1.5077639,-0.43770093,4998.5,1202.4899531174613,112.75000331550837,112.75000331550837,1.0
