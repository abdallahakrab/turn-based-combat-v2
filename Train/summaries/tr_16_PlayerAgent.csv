Steps,Policy/Entropy,Environment/Episode Length,Self-play/ELO,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,0.6931266,124.61538461538461,1198.4025911333022,-0.023008436,-0.07692307692307693,-0.07692307692307693,1.0
20000,0.6931279,149.78358208955223,1196.4663064394201,-0.025990093,-0.1044776119402985,-0.1044776119402985,1.0
30000,0.6858046,640.9666666666667,1195.009281699057,-0.042959377,0.3333333333333333,0.3333333333333333,1.0
40000,0.68525517,596.9705882352941,1196.3804906347088,-0.044647574,0.058823529411764705,0.058823529411764705,1.0
50000,0.6738649,259.2692307692308,1197.5779128259176,-0.0333524,0.07692307692307693,0.07692307692307693,1.0
60000,0.68314064,64.52980132450331,1192.5765246424996,0.1410003,-0.13333333333333333,-0.13333333333333333,1.0
70000,0.6912938,101.5204081632653,1190.7507977266127,0.08110837,0.0,0.0,1.0
80000,0.67965263,458.6,1187.967549258542,0.07061456,-0.23809523809523808,-0.23809523809523808,1.0
90000,0.68054384,791.5,1187.0467047184252,0.03604672,-0.4,-0.4,1.0
100000,0.68776137,551.9347826086956,1184.5210256145326,0.026910601,-0.043478260869565216,-0.043478260869565216,1.0
110000,0.68551606,69.89928057553956,1189.548955513058,0.011552112,0.057971014492753624,0.057971014492753624,1.0
120000,0.68688416,198.80612244897958,1190.1493092395444,0.014259042,-0.04,-0.04,1.0
130000,0.6860201,187.32692307692307,1188.537271374121,0.0010147413,0.0,0.0,1.0
140000,0.6596422,824.7,1187.6904871729544,-0.005030864,-0.2,-0.2,1.0
150000,0.6495127,459.53846153846155,1187.5399289657048,-0.0032617894,-0.23076923076923078,-0.23076923076923078,1.0
160000,0.6223216,857.65,1187.539928965705,0.038449317,0.4,0.4,1.0
