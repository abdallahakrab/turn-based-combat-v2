Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Self-play/ELO,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
210000,1.1382747,1.3298129,4999.5,1200.5,228.60001754760742,228.60001754760742,1.0
220000,1.1367176,1.4716213,4998.5,1200.9985608882907,215.50001733750105,215.50001733750105,1.0
230000,1.0934733,1.7117618,4998.5,1200.9985608882907,231.70001855492592,231.70001855492592,1.0
240000,1.0321419,1.7090652,4998.5,1200.9985608882907,243.00002212822437,243.00002212822437,1.0
250000,0.9733063,1.9986932,4998.5,1200.997123859483,249.2000213265419,249.2000213265419,1.0
260000,0.9687786,2.003725,4998.75,1200.9928210449903,267.6000260859728,267.6000260859728,1.0
270000,1.0405182,2.2114098,4998.5,1201.2413922762098,207.85001130402088,207.85001130402088,1.0
280000,0.9195921,2.3276691,4998.5,1201.9856751528825,243.2500220835209,243.2500220835209,1.0
